# README: Web Scraping de Mat√©ria do G1

Este projeto realiza um web scraping de uma mat√©ria publicada no site do G1. O objetivo √© extrair informa√ß√µes relevantes, como t√≠tulo, subt√≠tulo, autor, data de publica√ß√£o e conte√∫do da mat√©ria, e salv√°-las em um arquivo JSON limpo e organizado.

## Ferramentas Utilizadas

- **Linguagem**: Python
- **Bibliotecas**:
  - `requests`: Para realizar requisi√ß√µes HTTP e obter o c√≥digo HTML da p√°gina.
  - `BeautifulSoup` (da biblioteca `bs4`): Para fazer o parsing do HTML e navegar pelo conte√∫do da p√°gina.
  - `json`: Para salvar os dados extra√≠dos em um arquivo JSON.
  - `re` (Regex): Para realizar a limpeza e organiza√ß√£o dos dados.

## Funcionalidades do C√≥digo

### 1. Scraping da Mat√©ria
A fun√ß√£o `scrape_g1_article(url)` realiza as seguintes etapas:
- Faz uma requisi√ß√£o HTTP √† URL da mat√©ria do G1 usando `requests`.
- Analisa o HTML retornado com o `BeautifulSoup`.
- Extrai as seguintes informa√ß√µes:
  - **T√≠tulo**: A partir da tag `<h1>` com a classe `content-head__title`.
  - **Subt√≠tulo**: A partir da tag `<h2>` com a classe `content-head__subtitle`.
  - **Autor da mat√©ria**: A partir da tag `<span>` com a classe `content-publication-data__from`.
  - **Data de publica√ß√£o**: A partir da tag `<time>` com a classe `content-publication-data__updated`.
  - **Conte√∫do**: Todos os par√°grafos do conte√∫do principal, extra√≠dos da tag `<p>`.

Os dados s√£o organizados em um dicion√°rio com as seguintes chaves:
- `T√≠tulo`
- `Subt√≠tulo`
- `Autor da mat√©ria`
- `Data de publica√ß√£o`
- `Conte√∫do`

### 2. Limpeza dos Dados
A fun√ß√£o `clean_article_data(article_data)` utiliza regex para:
- Remover espa√ßos desnecess√°rios e caracteres redundantes nos valores dos dados.
- Assegurar que os dados estejam formatados e prontos para serem salvos.

### 3. Salvando os Dados
Os dados limpos s√£o salvos em um arquivo JSON chamado `g1_article_cleaned.json`. O arquivo √© codificado em UTF-8 para garantir a compatibilidade com caracteres especiais.

## Como Executar o C√≥digo

1. **Instale as depend√™ncias**:
   Certifique-se de que as bibliotecas `requests`, `bs4` e `re` estejam instaladas. Caso n√£o estejam, use o comando abaixo para instalar:
   ```bash
   pip install requests beautifulsoup4
   ```

2. **Defina a URL da Mat√©ria**:
   Verifique se a URL atribu√≠da √† vari√°vel `BASE_URL` corresponde √† p√°gina desejada.

3. **Execute o Script**:
   Rode o c√≥digo Python para realizar o scraping e salvar os dados:
   ```bash
   python nome_do_arquivo.py
   ```

4. **Verifique o Arquivo JSON**:
   Ao final da execu√ß√£o, os dados extra√≠dos estar√£o no arquivo `g1_article_cleaned.json`, localizado no mesmo diret√≥rio do script.

## Estrutura do JSON Gerado
O arquivo JSON gerado ter√° o seguinte formato:
```json
{
    "T√≠tulo": "T√≠tulo da mat√©ria",
    "Subt√≠tulo": "Subt√≠tulo da mat√©ria",
    "Autor da mat√©ria": "Nome do autor",
    "Data de publica√ß√£o": "2025-01-09T00:00:00",
    "Conte√∫do": "Texto completo da mat√©ria."
}
```

## Considera√ß√µes Finais
Este projeto foi desenvolvido como exemplo de web scraping simples, focado na extra√ß√£o de conte√∫do textual de uma p√°gina web. Ele pode ser adaptado para outros sites e formatos, desde que respeitadas as pol√≠ticas de uso do site alvo.

Se houver d√∫vidas ou sugest√µes de melhoria, entre em contato! üòä

